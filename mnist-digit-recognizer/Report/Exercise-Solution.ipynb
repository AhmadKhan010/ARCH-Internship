{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "128a7830",
   "metadata": {},
   "source": [
    "## Question No: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e3a933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\n",
    "X, y = mnist[\"data\"], mnist[\"target\"].astype(np.uint8)\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "\n",
    "# Scale pixel values to [0, 1]\n",
    "X_train_scaled = X_train / 255.0\n",
    "X_test_scaled = X_test / 255.0\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "# Initialize KNN classifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(knn_clf, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Train best model on full training set\n",
    "best_knn = grid_search.best_estimator_\n",
    "best_knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_knn = best_knn.predict(X_test_scaled)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"KNN Test Accuracy:\", accuracy_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565f4300",
   "metadata": {},
   "source": [
    "## Question No: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f422e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.ndimage import shift\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\n",
    "X, y = mnist[\"data\"], mnist[\"target\"].astype(np.uint8)\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "X_train_scaled = X_train / 255.0\n",
    "X_test_scaled = X_test / 255.0\n",
    "\n",
    "# Function to shift image by x, y pixels\n",
    "def shift_image(image, x, y):\n",
    "    return shift(image.reshape(28, 28), [y, x]).flatten()\n",
    "\n",
    "# Augment training set\n",
    "X_train_augmented = X_train_scaled.copy()\n",
    "y_train_augmented = y_train.copy()\n",
    "for x, y in [(1, 0), (-1, 0), (0, 1), (0, -1)]:  # Right, left, down, up\n",
    "    for image, label in zip(X_train_scaled, y_train):\n",
    "        X_train_augmented = np.vstack([X_train_augmented, shift_image(image, x, y)])\n",
    "        y_train_augmented = np.append(y_train_augmented, label)\n",
    "\n",
    "print(\"Augmented Training Set Shape:\", X_train_augmented.shape)  # (300000, 784)\n",
    "\n",
    "# Train best KNN model (from Exercise 1: n_neighbors=3, weights='distance')\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "knn_clf.fit(X_train_augmented, y_train_augmented)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_aug_knn = knn_clf.predict(X_test_scaled)\n",
    "accuracy_aug_knn = accuracy_score(y_test, y_pred_aug_knn)\n",
    "print(\"Augmented KNN Test Accuracy:\", accuracy_aug_knn)\n",
    "\n",
    "# Visualize a few augmented images\n",
    "for i in range(5):\n",
    "    plt.imshow(X_train_augmented[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Augmented Digit: {y_train_augmented[i]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27943bc",
   "metadata": {},
   "source": [
    "## Question No: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3220efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Note: Download Titanic dataset from https://www.kaggle.com/c/titanic\n",
    "# Or use Kaggle API: kaggle competitions download -c titanic\n",
    "# Place train.csv and test.csv in working directory\n",
    "\n",
    "# Load dataset\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess_titanic(df):\n",
    "    # Select features\n",
    "    features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "    X = df[features].copy()\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    X['Sex'] = X['Sex'].map({'male': 0, 'female': 1})\n",
    "    X = pd.get_dummies(X, columns=['Embarked'], drop_first=True)\n",
    "    \n",
    "    # Impute missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X[['Age', 'Fare']] = imputer.fit_transform(X[['Age', 'Fare']])\n",
    "    \n",
    "    return X\n",
    "\n",
    "# Prepare training data\n",
    "X = preprocess_titanic(train_df)\n",
    "y = train_df['Survived']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Train Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_val_scaled)\n",
    "print(\"Random Forest Validation Accuracy:\", accuracy_score(y_val, y_pred_rf))\n",
    "\n",
    "# Train Logistic Regression\n",
    "lr_clf = LogisticRegression(random_state=42)\n",
    "lr_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr_clf.predict(X_val_scaled)\n",
    "print(\"Logistic Regression Validation Accuracy:\", accuracy_score(y_val, y_pred_lr))\n",
    "\n",
    "# Prepare test set predictions (for Kaggle submission)\n",
    "X_test = preprocess_titanic(test_df)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_test_pred = rf_clf.predict(X_test_scaled)\n",
    "\n",
    "# Save submission\n",
    "submission = pd.DataFrame({'PassengerId': test_df['PassengerId'], 'Survived': y_test_pred})\n",
    "submission.to_csv('titanic_submission.csv', index=False)\n",
    "print(\"Submission file saved as 'titanic_submission.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb841e6",
   "metadata": {},
   "source": [
    "## Question No: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d20b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import email\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import re\n",
    "\n",
    "# Note: Download SpamAssassin datasets from https://spamassassin.apache.org/old/publiccorpus/\n",
    "# Place in 'spam' and 'ham' folders in working directory\n",
    "\n",
    "# Function to extract email body\n",
    "def extract_email_body(file_path):\n",
    "    with open(file_path, 'r', encoding='latin1') as f:\n",
    "        msg = email.message_from_file(f)\n",
    "        body = \"\"\n",
    "        if msg.is_multipart():\n",
    "            for part in msg.walk():\n",
    "                if part.get_content_type() == 'text/plain':\n",
    "                    body += part.get_payload(decode=True).decode('latin1', errors='ignore')\n",
    "        else:\n",
    "            body = msg.get_payload(decode=True).decode('latin1', errors='ignore')\n",
    "        # Clean text: lowercase, remove punctuation, numbers\n",
    "        body = re.sub(r'[^\\w\\s]', '', body.lower())\n",
    "        body = re.sub(r'\\d+', '', body)\n",
    "    return body\n",
    "\n",
    "# Load dataset\n",
    "spam_files = [os.path.join('spam', f) for f in os.listdir('spam') if f.endswith('.txt')]\n",
    "ham_files = [os.path.join('ham', f) for f in os.listdir('ham') if f.endswith('.txt')]\n",
    "\n",
    "# Extract email bodies\n",
    "emails = []\n",
    "labels = []\n",
    "for file in spam_files[:500] + ham_files[:500]:  # Limit for speed\n",
    "    emails.append(extract_email_body(file))\n",
    "    labels.append(1 if 'spam' in file else 0)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame({'email': emails, 'label': labels})\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['email'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create feature vectors\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Train Naive Bayes\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X_train_vec, y_train)\n",
    "y_pred_nb = nb_clf.predict(X_test_vec)\n",
    "print(\"Naive Bayes - Precision:\", precision_score(y_test, y_pred_nb))\n",
    "print(\"Naive Bayes - Recall:\", recall_score(y_test, y_pred_nb))\n",
    "print(\"Naive Bayes - F1 Score:\", f1_score(y_test, y_pred_nb))\n",
    "\n",
    "# Train SVM\n",
    "svm_clf = SVC(kernel='linear', random_state=42)\n",
    "svm_clf.fit(X_train_vec, y_train)\n",
    "y_pred_svm = svm_clf.predict(X_test_vec)\n",
    "print(\"SVM - Precision:\", precision_score(y_test, y_pred_svm))\n",
    "print(\"SVM - Recall:\", recall_score(y_test, y_pred_svm))\n",
    "print(\"SVM - F1 Score:\", f1_score(y_test, y_pred_svm))\n",
    "\n",
    "# Train Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train_vec, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test_vec)\n",
    "print(\"Random Forest - Precision:\", precision_score(y_test, y_pred_rf))\n",
    "print(\"Random Forest - Recall:\", recall_score(y_test, y_pred_rf))\n",
    "print(\"Random Forest - F1 Score:\", f1_score(y_test, y_pred_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
